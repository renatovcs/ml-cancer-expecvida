{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0140c8-5d4b-4299-aa00-740851bc417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "import pandas as pd  # Manipulação de dados\n",
    "from sklearn.model_selection import train_test_split  # Dividir os dados em treino e teste\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler  # Pré-processamento dos dados\n",
    "from sklearn.ensemble import RandomForestClassifier  # Algoritmo de classificação Random Forest\n",
    "from sklearn.metrics import classification_report, accuracy_score  # Avaliação do modelo\n",
    "from sklearn.ensemble import RandomForestRegressor  # Para o modelo de regressão Random Forest\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error  # Para avaliar o modelo\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86305757-1ab7-40d3-bc2d-47880c910e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do Modelo: 0.9649122807017544\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        71\n",
      "           1       0.98      0.93      0.95        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carregando o dataset de câncer de mama\n",
    "df_cancer = pd.read_csv(\"wisconsin.csv\")\n",
    "\n",
    "# Removendo colunas desnecessárias\n",
    "# A coluna 'id' é apenas um identificador e 'Unnamed: 32' está vazia\n",
    "df_limpo = df_cancer.drop(columns=['id', 'Unnamed: 32'])\n",
    "\n",
    "# Codificando a variável alvo (diagnóstico)\n",
    "# A coluna 'diagnosis' contém 'M' para maligno e 'B' para benigno\n",
    "# Vamos convertê-los para valores numéricos: M -> 1 e B -> 0\n",
    "le = LabelEncoder()\n",
    "df_limpo['diagnosis'] = le.fit_transform(df_limpo['diagnosis'])  # M -> 1, B -> 0\n",
    "\n",
    "# Separando as features (características) e o alvo (diagnóstico)\n",
    "# 'X' são todas as colunas de características e 'y' é a coluna alvo 'diagnosis'\n",
    "X = df_limpo.drop(columns='diagnosis')\n",
    "y = df_limpo['diagnosis']\n",
    "\n",
    "# Dividindo o dataset em conjuntos de treino e teste\n",
    "# Usamos 80% dos dados para treino e 20% para teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Padronizando as features para melhorar a performance do modelo\n",
    "# É importante que os dados estejam na mesma escala para algoritmos como o Random Forest\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Calcula a média e o desvio padrão e transforma os dados de treino\n",
    "X_test = scaler.transform(X_test)  # Transforma os dados de teste usando a mesma média e desvio padrão\n",
    "\n",
    "# Inicializando e treinando o classificador Random Forest\n",
    "# Random Forest é um algoritmo baseado em árvores de decisão, que combina várias árvores para melhorar a precisão\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)  # Treinando o modelo com os dados de treino\n",
    "\n",
    "# Fazendo previsões com o conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliando o modelo\n",
    "# Calculando a acurácia e gerando um relatório de classificação\n",
    "accuracy = accuracy_score(y_test, y_pred)  # Acurácia: porcentagem de previsões corretas\n",
    "classification_rep = classification_report(y_test, y_pred)  # Relatório detalhado: precisão, recall e F1-score para cada classe\n",
    "\n",
    "# Exibindo os resultados\n",
    "print(\"Acurácia do Modelo:\", accuracy)\n",
    "print(\"Relatório de Classificação:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd95ade1-164c-4453-9c26-0b4bbdbdcba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1219969696969752, 1.9121251282436036)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando o dataset de expectativa de vida\n",
    "df_expec = pd.read_csv(\"expectancy.csv\")\n",
    "\n",
    "# Removendo colunas irrelevantes\n",
    "# 'Country' e 'Year' não são relevantes para o modelo, então vamos removê-las\n",
    "df_expec_limpo = df_expec.drop(columns=['Country', 'Year'])\n",
    "\n",
    "# Codificando a variável categórica \"Status\"\n",
    "# Convertendo 'Status' (desenvolvido ou em desenvolvimento) em valores numéricos\n",
    "df_expec_limpo['Status'] = LabelEncoder().fit_transform(df_expec_limpo['Status'])\n",
    "\n",
    "# Removendo linhas com valores ausentes\n",
    "# Para simplificar, vamos descartar qualquer linha que tenha valores faltantes\n",
    "df_expec_limpo = df_expec_limpo.dropna()\n",
    "\n",
    "# Separando as features (características) e a variável alvo (expectativa de vida)\n",
    "# 'X' contém todas as colunas de características, enquanto 'y' é a coluna alvo 'Life expectancy '\n",
    "X = df_expec_limpo.drop(columns='Life expectancy ')\n",
    "y = df_expec_limpo['Life expectancy ']\n",
    "\n",
    "# Dividindo o dataset em conjuntos de treino e teste\n",
    "# Usamos 80% dos dados para treino e 20% para teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Padronizando as features para melhorar a performance do modelo\n",
    "# Colocando todas as variáveis na mesma escala para que o modelo funcione melhor\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Calcula média e desvio padrão e transforma os dados de treino\n",
    "X_test = scaler.transform(X_test)  # Transforma os dados de teste com a mesma escala\n",
    "\n",
    "# Inicializando e treinando o modelo de regressão Random Forest\n",
    "# RandomForestRegressor é adequado para prever valores numéricos contínuos, como a expectativa de vida\n",
    "regressor = RandomForestRegressor(random_state=42)\n",
    "regressor.fit(X_train, y_train)  # Treinando o modelo com os dados de treino\n",
    "\n",
    "# Fazendo previsões com o conjunto de teste\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Avaliando o modelo\n",
    "# Calculando o erro absoluto médio (MAE), o erro quadrático médio (MSE) e a raiz do erro quadrático médio (RMSE)\n",
    "mae = mean_absolute_error(y_test, y_pred)  # MAE: média da diferença absoluta entre valores reais e previstos\n",
    "mse = mean_squared_error(y_test, y_pred)  # MSE: média da diferença ao quadrado entre valores reais e previstos\n",
    "rmse = mse ** 0.5  # RMSE: raiz quadrada do MSE, facilitando a interpretação em termos da unidade original\n",
    "\n",
    "# Exibindo os resultados\n",
    "mae, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c53bf5a-742a-47e3-8e49-f0e3a55352a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.005518988407021, 2.744254698741196)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando o dataset e removendo colunas irrelevantes\n",
    "df_expec = pd.read_csv(\"expectancy.csv\")\n",
    "df_expec_limpo = df_expec.drop(columns=['Country', 'Year'])\n",
    "\n",
    "# Codificando a variável categórica \"Status\" (Desenvolvido ou Em Desenvolvimento)\n",
    "df_expec_limpo['Status'] = LabelEncoder().fit_transform(df_expec_limpo['Status'])\n",
    "\n",
    "# Removendo linhas com valores faltantes\n",
    "df_expec_limpo = df_expec_limpo.dropna()\n",
    "\n",
    "# Reduzindo o dataset para 10% dos dados originais\n",
    "# Isso cria uma amostra menor para simplificar o treinamento do modelo\n",
    "data_sampled_smaller = df_expec_limpo.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# Separando características (X) e variável alvo (y) com a amostra menor\n",
    "X_sampled_smaller = data_sampled_smaller.drop(columns='Life expectancy ')\n",
    "y_sampled_smaller = data_sampled_smaller['Life expectancy ']\n",
    "\n",
    "# Dividindo o conjunto de dados reduzido em treino e teste\n",
    "# Aqui, 80% dos dados são usados para treino e 20% para teste\n",
    "X_train_sampled_smaller, X_test_sampled_smaller, y_train_sampled_smaller, y_test_sampled_smaller = train_test_split(\n",
    "    X_sampled_smaller, y_sampled_smaller, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Inicializando e treinando o modelo XGBoost com configuração simplificada na amostra menor\n",
    "xgb_model_sampled_smaller = XGBRegressor(random_state=42, objective='reg:squarederror', n_estimators=50, max_depth=3)\n",
    "xgb_model_sampled_smaller.fit(X_train_sampled_smaller, y_train_sampled_smaller)\n",
    "\n",
    "# Fazendo previsões com o conjunto de teste\n",
    "y_pred_xgb_sampled_smaller = xgb_model_sampled_smaller.predict(X_test_sampled_smaller)\n",
    "\n",
    "# Avaliando o modelo XGBoost treinado na amostra menor\n",
    "mae_xgb_sampled_smaller = mean_absolute_error(y_test_sampled_smaller, y_pred_xgb_sampled_smaller)\n",
    "rmse_xgb_sampled_smaller = mean_squared_error(y_test_sampled_smaller, y_pred_xgb_sampled_smaller) ** 0.5\n",
    "\n",
    "# Exibindo MAE e RMSE para o modelo XGBoost com a amostra reduzida\n",
    "mae_xgb_sampled_smaller, rmse_xgb_sampled_smaller\n",
    "\n",
    "# Configuração ainda mais simplificada do XGBoost com menos estimadores e profundidade menor\n",
    "# Isso torna o modelo mais leve e rápido, ideal para testes rápidos\n",
    "xgb_model_minimal = XGBRegressor(random_state=42, objective='reg:squarederror', n_estimators=10, max_depth=2)\n",
    "xgb_model_minimal.fit(X_train_sampled_smaller, y_train_sampled_smaller)\n",
    "\n",
    "# Fazendo previsões com o conjunto de teste para o modelo minimalista\n",
    "y_pred_xgb_minimal = xgb_model_minimal.predict(X_test_sampled_smaller)\n",
    "\n",
    "# Avaliando o modelo XGBoost minimalista\n",
    "mae_xgb_minimal = mean_absolute_error(y_test_sampled_smaller, y_pred_xgb_minimal)\n",
    "rmse_xgb_minimal = mean_squared_error(y_test_sampled_smaller, y_pred_xgb_minimal) ** 0.5\n",
    "\n",
    "# Exibindo MAE e RMSE para o modelo XGBoost minimalista\n",
    "mae_xgb_minimal, rmse_xgb_minimal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
